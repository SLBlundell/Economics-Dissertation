{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Econometric Specification Codebook \n",
    "### Applied Economics Dissertation: Herding in Chinese Equity Markets in Response to COVID-19 'Lockdown Style' Containment Measures - Sam Blundell"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This codebooks's purpose is to create a timeseries dataset of the primary regression specification used within this Economics dissertation. The regression specification, following the approach utilised by Christie & Huang (1995) and Chang et al. (2000), takes the following form:\n",
    "\n",
    ">$CSSD_t=γ_0+γ_1 R_{m,t}+γ_2 |R_{m,t}|+γ_3 R_{m,t}^2+γ_4STRINGENCY_t+ε_t$\n",
    "\n",
    "Where $CSAD$ is a measure of dispersion of Chinese equity returns, $R_m$ is an average of the market portfolio return and $STRINGENCY$ is the Oxford University COVID-19 Government Response Tracker's measure of 'lockdown style' policies in China: https://www.bsg.ox.ac.uk/research/covid-19-government-response-tracker."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constructing the Time Series Dataset\n",
    "The following code creates the methods necessary to construct the regression specification. Namely, it calculates the following variables:\n",
    "\n",
    "$R_{i,t}=100\\times(\\ln{P_{i,t}}-\\ln{P_{i,t-1}}),$\n",
    "\n",
    "$R_{m,t}=\\frac{1}{N}\\sum^N_{i=1}{R_{i,t}},$\n",
    "\n",
    "$CSAD_t=\\frac{1}{N}\\sum^N_{i=1}{|R_{i,t}-R_{m,t}|},$\n",
    "\n",
    "$CSSD_t=\\sqrt{\\frac{\\sum^N_{i=1}{(R_{i,t}-R_{m,t})^2}}{N-1}},$\n",
    "\n",
    "where $P_{i,t}$ is the close price of equity $i$ on date $t$ and $N$ is the number of days in the sample. These variables are placed within a time series dataset, with each row representing the specification for a given value of $t$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "class DataProcessor:\n",
    "    \"\"\"\n",
    "    Represents the processing of given data into the primary regression specification\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, returns_file, stringency_file):\n",
    "        self.df = returns_file\n",
    "        self.df_stringency = stringency_file\n",
    "        self.df_spec = pd.DataFrame(columns=['date', 'R_m', 'CSAD', 'CSSD', 'stringency'])\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "        returns_file : DataFrame\n",
    "            DataFrame containing market data for selected equities recieved from the TuShare API\n",
    "        stringency_file : DataFrame\n",
    "            DataFrame containing dates and corresponding stringency index for China\n",
    "        \"\"\"\n",
    "\n",
    "    def sort_data(self):\n",
    "        \"\"\"Sorts data based on equity code, then ascending date\"\"\"\n",
    "        self.df = self.df.sort_values(by=['ts_code', 'trade_date']).reset_index(drop=True)\n",
    "\n",
    "    def calculate_log_returns(self):\n",
    "        \"\"\"Calculates daily logarithmic returns for all dates\"\"\"\n",
    "        pd.to_numeric(self.df['close'])\n",
    "        self.df['daily_log_return'] = 100 * (np.log(self.df['close'].astype('float')) \n",
    "                                             - np.log(self.df['close'].astype('float').shift(1)))\n",
    "        self.df.loc[self.df['Date'] == 20200102, 'daily_log_return'] = np.nan\n",
    "\n",
    "    def calculate_return_market(self, date):\n",
    "        \"\"\"Calculates the market return, being the equally-weighted arithmetic mean of individual equity log-returns on a given date\"\"\"\n",
    "        return np.mean(self.get_returns_on_date(date))\n",
    "\n",
    "    def calculate_CSAD(self, date, R_m):\n",
    "        \"\"\"Calculates CSAD on a given date\"\"\"\n",
    "        returns_on_date = self.get_returns_on_date(date)\n",
    "        return (1/self.df['ts_code'].nunique()) * np.sum(np.abs([x - R_m for x in returns_on_date]))\n",
    "\n",
    "    def calculate_CSSD(self, date, R_m):\n",
    "        \"\"\"Calculates CSSD on a given date\"\"\"\n",
    "        returns_on_date = self.get_returns_on_date(date)\n",
    "        return (1/(self.df['ts_code'].nunique() - 1)) * np.sum([(x - R_m) ** 2 for x in returns_on_date]) ** (1/2)\n",
    "\n",
    "    def get_returns_on_date(self, date):\n",
    "        \"\"\"Returns list of all logarithmic equity returns on a given date\"\"\"\n",
    "        return self.df.loc[self.df['trade_date'] == date, 'daily_log_return'].tolist()\n",
    "\n",
    "    def process_data(self):\n",
    "        \"\"\"Iterates through all unique dates within datasets, creating a row of all variables within the regression specification,\n",
    "        and appending the main specification dataset with said rows\"\"\"\n",
    "        self.calculate_log_returns()\n",
    "        \n",
    "        for date in self.df.trade_date.unique().tolist():\n",
    "            R_m = self.calculate_return_market(date)\n",
    "            CSAD = self.calculate_CSAD(date, R_m)\n",
    "            CSSD = self.calculate_CSSD(date, R_m)\n",
    "            stringency = self.df_stringency.loc[self.df_stringency['Date'] == int(date), 'StringencyIndex_WeightedAverage'].item()\n",
    "            new_row = pd.DataFrame({'date' : date, \n",
    "                                 'R_m' : R_m, \n",
    "                                 'CSAD' : CSAD,\n",
    "                                 'CSSD' : CSSD,\n",
    "                                 'stringency' : stringency}, \n",
    "                                index=[0])\n",
    "            self.df_spec = pd.concat([self.df_spec, new_row], ignore_index=True)\n",
    "\n",
    "    def save_data(self, output_file):\n",
    "        \"\"\"Saves the dataset of timeseries data to a comma-deliminated file (csv)\"\"\"\n",
    "        self.df_spec.to_csv(output_file)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we gather our Chinese equity market data, utilizing the China-based community run API TuShare https://tushare.pro/. \n",
    "\n",
    "The `daily_log_return` column of the resultant dataset represents $R_{i,t}$ within our variables $CSAD_t$ and $CSSD_t$, with $t$ being the `trade_date` and $i$ the `ts_code`.\n",
    "\n",
    "BE WARNED: \n",
    "Due to the community nature of the TuShare API, only 6000 values can be requested at once for most users. As such, the method below splits the data requests into 20 day batches, which results in a considerably long runtime for the whole 3-year period."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tushare as ts\n",
    "import re\n",
    "\n",
    "class GetChineseEquityData:\n",
    "    \"\"\"Represents code necessary to retrieve data from TuShare API\"\"\"\n",
    "\n",
    "    def __init__(self, list_path, start_date, end_date):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "        list_path : Literal\n",
    "            The list of equities you are retrieving data for. Data should be csv file, \n",
    "            containing the column name \"code\" with all your equity codes and \"exchange\" containing the equity's exchange.\n",
    "        start_date : int\n",
    "            The start date of the period you want to retrieve data for\n",
    "        end_date : int\n",
    "            The end date of the period you want to retrieve data for\n",
    "        \"\"\"\n",
    "        \n",
    "        self.list_path = list_path\n",
    "        self.start_date = start_date\n",
    "        self.end_date = end_date\n",
    "        self.df_codes = pd.read_csv(list_path)\n",
    "        ts.set_token('2a7bf16f7b6d0214eda80e1e2ed1aec6e8e48a6f2a52ced7792e6dc2')\n",
    "        self.pro = ts.pro_api()\n",
    "\n",
    "    def get_codes(self):\n",
    "        \"\"\"Returns a string of codes separated by commas.\"\"\"\n",
    "        return ','.join([\n",
    "            f\"{row['code'][0:6]}.SH\" if row['exchange'] == 'Shanghai' \n",
    "            else f\"{row['code'][0:6]}.SZ\" \n",
    "            for _, row in self.df_codes.iterrows()\n",
    "        ])\n",
    "\n",
    "    def get_returns_data(self):\n",
    "        \"\"\"Retrieves market data for all equities in the list within the specified date range\n",
    "        using batch queries.\"\"\"\n",
    "        codes = self.get_codes()\n",
    "        t = self.start_date\n",
    "        appended_data = []\n",
    "        \n",
    "        while t < self.end_date:\n",
    "            data = self.pro.daily(ts_code=codes, start_date=str(t), end_date=str(t + 20), chunksize=5000)\n",
    "            appended_data.append(data)\n",
    "            t += 21\n",
    "        \n",
    "        appended_data = pd.concat(appended_data)\n",
    "        return appended_data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This project uses a \"market portfolio\" comprising of the component stocks of the CSI 300, an index of the largest 300 stocks on the Shanghai Stock Exchange and Shenzhen Stock Exchange (as of January 1st 2020). The dates chosen ensure a period before any COVID measures is contained within the dataset for robustness, in addition to the whole COVID-19 period until 2023."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csi_list_path = r'C:/Users/whisk/OneDrive/Documents/Bristol/Economics/Year 4/AED/Small Group Sessions/Section 2/Data/csi_constituents.csv'\n",
    "data_components = GetChineseEquityData(csi_list_path, 20200101, 20230101)\n",
    "returns_data = data_components.get_returns_data()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting the COVID-19 Government Response data from the Oxford COVID Policy Tracker's GitHub https://github.com/OxCGRT/covid-policy-tracker:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import io\n",
    "\n",
    "class GetStringencyData:\n",
    "\n",
    "    def __init__(self, years):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "        years : List\n",
    "            List of years you want data retrieved for, in string format\n",
    "        \"\"\"\n",
    "\n",
    "        self.url_base = \"https://raw.githubusercontent.com/OxCGRT/covid-policy-tracker/master/data/OxCGRT_nat_differentiated_withnotes_{}.csv\"\n",
    "        self.years = years\n",
    "        self.stringency_data = pd.DataFrame(columns=['Date', 'StringencyIndex_WeightedAverage'])\n",
    "\n",
    "    def get_data(self, year):\n",
    "        \"\"\"requests HTML content from the OxCGRT GitHub, returns content in a DataFrame\"\"\"\n",
    "        url = self.url_base.format(year)\n",
    "        data = requests.get(url).content\n",
    "        df = pd.read_csv(io.StringIO(data.decode('utf-8')))\n",
    "        return df\n",
    "\n",
    "    def filter_data(self, df):\n",
    "        \"\"\"Filters data so that only dates and Stringency Index for China is included\"\"\"\n",
    "        df = df.loc[df['CountryName'] == 'China']\n",
    "        df = df[['Date', 'StringencyIndex_WeightedAverage']].replace(np.nan, 0)\n",
    "        return df\n",
    "\n",
    "    def concatenate_data(self, df):\n",
    "        \"\"\"Combines data for each year specified into one DataFrame\"\"\"\n",
    "        self.stringency_data = pd.concat([self.stringency_data, df]).reset_index(drop=True)\n",
    "\n",
    "    def get_and_filter(self):\n",
    "        \"\"\"Iterates over each year specified, retrieving and filtering data from OxCGRT GitHub\"\"\"\n",
    "        for year in self.years:\n",
    "            df = self.get_data(year)\n",
    "            df = self.filter_data(df)\n",
    "            self.concatenate_data(df)\n",
    "        \n",
    "        return self.stringency_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sd = GetStringencyData([\"2020\", \"2021\", \"2022\", \"2023\"])\n",
    "stringency_data = sd.get_and_filter()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we can run our data processor, which returns a dataset of rows representing our primary specification at each value of $t$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_processor = DataProcessor(returns_data, stringency_data)\n",
    "data_processor.sort_data()\n",
    "data_processor.process_data()\n",
    "data_processor.save_data('spec_1_stringency_CSSD_CSAD.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "bcf767d74aa0613621d814dbc311c100d7c513475831bdee7c609a7f5e52ccf1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
